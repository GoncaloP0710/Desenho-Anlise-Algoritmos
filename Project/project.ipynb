{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31113be5",
   "metadata": {},
   "source": [
    "# Persistent Data Structures\n",
    "\n",
    "#### Goncalo Pinto - fc58178\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<a href=\"#introduction\"><kbd> <br>Introduction<br> </kbd></a>&ensp;&ensp;\n",
    "<a href=\"#motivation\"><kbd> <br>Motivation & historical background<br> </kbd></a>&ensp;&ensp;\n",
    "<a href=\"#design\"><kbd> <br>Design of the algorithms<br> </kbd></a>&ensp;&ensp;\n",
    "<a href=\"#reference\"><kbd> <br>References<br> </kbd></a>&ensp;&ensp;\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd595e15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### `setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "36e81082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyrsistent in /home/goncalop0710/Desktop/Faculdade/Desenho e Análise de Algoritmos/TPs/.venv/lib/python3.13/site-packages (0.20.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the pyrsistent library\n",
    "!pip install pyrsistent\n",
    "\n",
    "from pyrsistent import pvector, pmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed9b1e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "---\n",
    "<a id=\"introduction\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Introduction\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b067d",
   "metadata": {},
   "source": [
    "In this chapter, we will analyze concepts that define a persistent data structure as well as present algorithmic tools that attempt to implement them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea556db1",
   "metadata": {},
   "source": [
    "## Persistent Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5444cf1",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b873b42b",
   "metadata": {},
   "source": [
    "A persistent data structure or **not ephemeral** data structure is a data structure that preserves the previous counters of itself when modified, allowing access to any historical counter. In other words, once a change is made to the structure, both the original and modified counters remain accessible. This is particularly useful in scenarios where you need to keep track of the history of updates or backtrack to previous states of the data structure.\n",
    "\n",
    "Persistent data structures are usually related to functional and logical programming due to their nature of avoiding **mutable data**. Persistent data structures are **immutable**. Once written they can never change. Once you read it, there are guarantees that nothing can change its state. Any updates to the persistent data structures result in the creation of a new version, so any older states of the data stay intact.\n",
    "\n",
    "There are multiple types of persistent data structures:\n",
    "\n",
    "- A data structure is `partially persistent` if all counters can be accessed but only the newest counter can be modified. \n",
    "- `Fully persistent` if every counter can be both accessed and modified. \n",
    "- `Confluently persistent` is when we merge two or more counters to get a new counter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb81fe",
   "metadata": {},
   "source": [
    "### Example of Persistent binary search tree\n",
    "\n",
    "The code was taken from the article on Persistent Data Structures available at [GeeksforGeeks](https://www.geeksforgeeks.org/persistent-data-structures/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fe799",
   "metadata": {},
   "source": [
    "Imagine a binary tree structure where instead of modifying the fields of a node whenever we want to update it, we create a new version of the same tree, keeping the older ones in memory. Due to that decision, we still have access to the previous versions of the tree, being able to revert to any state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749db18a",
   "metadata": {},
   "source": [
    "<center><img src='https://raw.githubusercontent.com/GoncaloP0710/Desenho-Anlise-Algoritmos/master/imgs/persistent-Tree.png' width=500px></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b128c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node class represents a node in the binary search tree\n",
    "class Node:\n",
    "    def __init__(self, key):\n",
    "        self.key = key  # key value of the node\n",
    "        self.left = None  # pointer to the left child\n",
    "        self.right = None  # pointer to the right child\n",
    " \n",
    "# BST class implements a binary search tree\n",
    "class BST:\n",
    "    def __init__(self):\n",
    "        self.root = None  # root node of the tree\n",
    " \n",
    "    # Function to create a new node with given key\n",
    "    def create_node(self, key):\n",
    "        return Node(key)\n",
    " \n",
    "    # Function to insert a new key into the tree\n",
    "    def insert(self, root, key):\n",
    "        if root is None:\n",
    "            return self.create_node(key)\n",
    "        if key < root.key:\n",
    "            root.left = self.insert(root.left, key)\n",
    "        elif key > root.key:\n",
    "            root.right = self.insert(root.right, key)\n",
    "        return root\n",
    " \n",
    "    # Function to create a copy of the tree\n",
    "    def copy_tree(self, root):\n",
    "        if root is None:\n",
    "            return None\n",
    "        new_node = self.create_node(root.key)\n",
    "        new_node.left = self.copy_tree(root.left)\n",
    "        new_node.right = self.copy_tree(root.right)\n",
    "        return new_node\n",
    " \n",
    "    # Function to create a persistent copy of the tree and insert a new key\n",
    "    def make_persistent(self, key):\n",
    "        new_bst = BST()\n",
    "        new_bst.root = self.copy_tree(self.root)\n",
    "        new_bst.root = new_bst.insert(new_bst.root, key)\n",
    "        return new_bst\n",
    " \n",
    "    # Function to print the keys of the nodes in ascending order\n",
    "    def print_in_order(self, root):\n",
    "        if root is not None:\n",
    "            self.print_in_order(root.left)\n",
    "            print(root.key, end=\" \")\n",
    "            self.print_in_order(root.right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "70b9de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BST1: 20 30 40 50 60 70 80 \n",
      "BST2: 20 30 40 50 55 60 70 80 \n"
     ]
    }
   ],
   "source": [
    "# Driver Code\n",
    "if __name__ == \"__main__\":\n",
    "    bst1 = BST()\n",
    "    bst1.root = bst1.insert(bst1.root, 50)\n",
    "    bst1.root = bst1.insert(bst1.root, 30)\n",
    "    bst1.root = bst1.insert(bst1.root, 20)\n",
    "    bst1.root = bst1.insert(bst1.root, 40)\n",
    "    bst1.root = bst1.insert(bst1.root, 70)\n",
    "    bst1.root = bst1.insert(bst1.root, 60)\n",
    "    bst1.root = bst1.insert(bst1.root, 80)\n",
    " \n",
    "    # Create a persistent copy of bst1 and insert a new key\n",
    "    bst2 = bst1.make_persistent(55)\n",
    " \n",
    "    # Print the keys of the nodes in bst1\n",
    "    print(\"BST1: \", end=\"\")\n",
    "    bst1.print_in_order(bst1.root)\n",
    "    print()\n",
    " \n",
    "    # Print the keys of the nodes in bst2\n",
    "    print(\"BST2: \", end=\"\")\n",
    "    bst2.print_in_order(bst2.root)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57232092",
   "metadata": {},
   "source": [
    "#### Persistent binary search trees: BST1 & BST2\n",
    "\n",
    "BST1:\n",
    "- This is the original binary search tree.\n",
    "- The keys in the tree are [20, 30, 40, 50, 60, 70, 80].\n",
    "\n",
    "BST2:\n",
    "- This is a persistent copy of BST1 with an additional key 55 inserted.\n",
    "- The keys in the tree are [20, 30, 40, 50, 55, 60, 70, 80].\n",
    "- The new key 55 is inserted in the correct position to maintain the binary search tree property.\n",
    "\n",
    "> This demonstrates how each version of the tree is immutable and builds upon the previous version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16af0b8",
   "metadata": {},
   "source": [
    "### Example of Persistent List & Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8b14540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original list: pvector([1, 2, 3])\n",
      "New list:      pvector([1, 2, 3, 4])\n",
      "Original dictionary: pmap({'a': 1, 'c': 3, 'b': 2})\n",
      "New dictionary:      pmap({'d': 4, 'a': 1, 'c': 3, 'b': 2})\n"
     ]
    }
   ],
   "source": [
    "# Immutable list\n",
    "original_list = pvector([1, 2, 3])\n",
    "new_list = original_list.append(4)\n",
    "\n",
    "print(\"Original list:\", original_list)\n",
    "print(\"New list:     \", new_list)\n",
    "\n",
    "# Immutable dictionary\n",
    "original_dict = pmap({'a': 1, 'b': 2, 'c': 3})\n",
    "new_dict = original_dict.set('d', 4)\n",
    "\n",
    "print(\"Original dictionary:\", original_dict)\n",
    "print(\"New dictionary:     \", new_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca90d5",
   "metadata": {},
   "source": [
    "The code above shows a persistent list and dictionary. As you can see, each update creates a new version of the data structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3c0319",
   "metadata": {},
   "source": [
    "## Implementing Persistent Data Structures\n",
    "\n",
    "In order to implement a well-structured persistent data structure, we first need to create algorithms to manage and control all of the existing versions in an optimized way in order to prevent excessive memory overhead.\n",
    "\n",
    "- Structural Sharing\n",
    "- Copy-on-Write\n",
    "- Fat Nodes\n",
    "- Path Copying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29c613",
   "metadata": {},
   "source": [
    "### Structural Sharing\n",
    "\n",
    "In functional programming, it's possible to save a large amount of memory by employing structural sharing.\n",
    "\n",
    "Structural sharing is an efficient technique used in data structures to build new versions of data without creating unchanged data again. It’s especially common in persistent (immutable) data structures. The basic idea of structural sharing is to reuse data instead of copying it once more.\n",
    "\n",
    "> \" It’s kind of similar to the way Git manages multiple versions of your source code: Git doesn’t copy all the files on each commit. Instead, the files that are not changed by a commit are shared with previous commits.\" (Yehonathan Sharvit, Developer. Author. Speaker.)\n",
    "\n",
    "Path copying is usually efficient in terms of memory and computation because of the way the copies are done. When copying a node, only its reference is in fact being copied and not the entire object. This is called a shallow copy.\n",
    "\n",
    "Path copying works fine with deeply nested data where at each nesting level we don’t have too many elements. When we have many elements at some level, shallow copying might be an issue. Suppose we have a million users in our system—copying a million references each time we update the password of a user won’t scale.\n",
    "- The same issue occurs with Git if you have a folder with too many files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05cae9",
   "metadata": {},
   "source": [
    "<center><img src='https://raw.githubusercontent.com/GoncaloP0710/Desenho-Anlise-Algoritmos/master/imgs/structural_sharing.png' width=500px></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb706c8",
   "metadata": {},
   "source": [
    "### Copy-on-Write\n",
    "\n",
    "> Copy-on-Write is at its most useful when the data is mutable.\n",
    "\n",
    "Copy-on-write, also called implicit sharing or shadowing, is a resource-management technique used to manage shared data efficiently. If multiple resources are working with the same data, this technique won’t let them create a new copy of the data, in order to save resources, and will force them to share the same memory initially. Instead, a copy is only created when a process needs to write something on the data. Only then, a private copy is done!\n",
    "\n",
    "This approach is commonly used on forking operations and virtual memory.\n",
    "- > Note: virtual memory abstracts physical RAM, giving each process its own virtual address space.\n",
    "\n",
    "Copy-on-write can be implemented efficiently using the page table data structure. The page table maps virtual pages to physical frames. When a process is forked using the Copy-on-Write approach, the memory is not all copied and instead part of it becomes read-only. When a write operation takes place, the OS will get a page fault due to the write attempt on a read-only page and will check for a Copy-on-Write flag. Only then, a new physical copy is created and updated.\n",
    "\n",
    "\n",
    "#### Pros\n",
    "- Reduces unnecessary copying (memory wasted)\n",
    "- Improves performance (less copying)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fca708",
   "metadata": {},
   "source": [
    "<center><img src='https://raw.githubusercontent.com/GoncaloP0710/Desenho-Anlise-Algoritmos/master/imgs/Copy-on-write-example.png' width=500px></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471f673",
   "metadata": {},
   "source": [
    "### The Fat Node Method\n",
    "\n",
    "General theoretical schemes are known (e.g. the fat node method ) for making any data structure partially persistent. The fat node method as proposed by Driscoll[4] is used to transform an ephemeral structure into a partially persistent structure in which versions of fields are saved in the node itself without erasing old values of fields. Although the fat node method was originally described only for data structures in the pointer model of computation, it can be generalized as seen on the paper: Implementing Partial Persistence in Object-Oriented Languages[6].\n",
    "\n",
    "> This means each field of a node must contain its corresponding version.\n",
    "\n",
    "#### Pros\n",
    "- Enables easy access to past versions of the data.\n",
    "- No need to copy nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d598e27a",
   "metadata": {},
   "source": [
    "<font size=\"+4\" color=\"blue;green\"><b>?</b></font> Wont the Node become a super complex structure the more updates are made? And wont that impact Structural Sharing?\n",
    "\n",
    "Yes, if nothing is done the node will eventualy carry too many versions and make the Structural Sharing impossible to work well.\n",
    "\n",
    "In that case, we must add another startagy -> `Node-Copying Method`\n",
    "- Each node has a limit to the amount of fields it has\n",
    "- When the limit is reached it must be copied (separated in 2 different nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39092f4e",
   "metadata": {},
   "source": [
    "### Path copying\n",
    "\n",
    "Path copying is a technique used to make data structures partially or fully persistent. The core idea is to create a copy of the path that leads to the node being updated. Once the copy is made, the root of the structure is updated to point to the new root, which reflects the changes. This approach allows us to preserve all previous versions of the data structure, enabling access to previous states.\n",
    "\n",
    "To maintain consistency, it is crucial to ensure that all nodes pointing to the old node are updated to point to the newly created node. This guarantees that the structure remains valid and that no references to outdated nodes exist in the updated version.\n",
    "\n",
    "Path copying can lead to increased memory usage, as multiple copies of the path are created for each update. To mitigate this, techniques like structural sharing can be employed to reuse unchanged parts of the structure, reducing memory overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d221b537",
   "metadata": {},
   "source": [
    "<center><img src='https://raw.githubusercontent.com/GoncaloP0710/Desenho-Anlise-Algoritmos/master/imgs/path-copying.png' width=500px></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae0132",
   "metadata": {},
   "source": [
    "## Partially persistent data structure\n",
    "\n",
    "A partially persistent data structure is a data structure where all of its versions can be observed and accessed. However, only the latest version can be modified.This makes it particularly useful in scenarios where tracking changes over time is important.\n",
    "\n",
    "#### Pros\n",
    "\n",
    "- You have access to any previous version of the data.\n",
    "- Easier to implement and more efficient than fully or confluently persistent structures.\n",
    "- Extra memory needed is often limited.\n",
    "- Offers worst-case guarantees, complexity of updates and queries are predictable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067be8c",
   "metadata": {},
   "source": [
    "## Fully persistent data structure\n",
    "\n",
    "A fully persistent structure allows to observe and modify all of the versions that exist, where each update operation on a version creates a new branch from this version to the new one (kinda like github in a way).\n",
    "\n",
    "In a fully persistent structure, if update operation i applies to version j < i, the result of the update is version i; version j is not changed by the update. We denote by n the number of nodes in the current version.\n",
    "\n",
    "#### Pros\n",
    "\n",
    "- Any version can be modified, not just the latest — each update creates a new branch in the version tree.\n",
    "- Ideal for situations where different branches of computation must operate independently from the same data snapshot.\n",
    "- Old versions remain unchanged, ensuring a safe enviroment to modify other versions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ad8dd",
   "metadata": {},
   "source": [
    "## Confluently persistent data structure\n",
    "\n",
    "A data structure is called confluently persistent if there is a meld operation that creates a new version from two previous versions so that branches in a version tree are joined and a version DAG (Directed Acyclic Graph) is formed.\n",
    "- It’s acyclic because versions never point backward — no version can be its own ancestor.\n",
    "\n",
    "\n",
    "Confluently Persistent Sets and Maps are functional binary search trees that support efficient set operations both when the structures are disjoint and when they are overlapping. Confluently persistent functional sets and maps can be implemented using avl trees, red-black, or treaps.\n",
    "\n",
    "#### Pros\n",
    "\n",
    "- Supports a meld operation: two or more past versions can be merged to create a new version\n",
    "- Unlike full persistence (which forms a tree), confluent persistence allows merging branches into a directed acyclic graph (DAG) of versions.\n",
    "- Ideal for use cases involving merging divergent states (distributed systems, version control...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5bed0",
   "metadata": {},
   "source": [
    "<a id=\"motivation\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"motivation&historicalbackground\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Motivation &\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97517ee1",
   "metadata": {},
   "source": [
    "The motivation for using and continuously improving persistent data structures lies in their ability to maintain previous states and support various operations on those states.\n",
    "\n",
    "Some pratical exemples where this structures are optimaly used are:\n",
    "- Version Control (ex: git)\n",
    "- Undo/Redo Functionality (ex: text editor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c22198",
   "metadata": {},
   "source": [
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Background\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff3660",
   "metadata": {},
   "source": [
    "The concept of persistent data structures was introduced in Driscoll, Sarnak, Sleator, and Tarjan's 1986 article \"Making Data Structures Persistent\".\n",
    "\n",
    "The paper explores the advantages of using a data structure powerful enough to store previous stages of itself and compares it to an ephemeral one. It also exposed the 3 different types of persistence: Partial Persistence, Full Persistence, and Confluent Persistence.\n",
    "\n",
    "The study introduced different techniques such as: the Fat Node Method, the Node-Copying Method, or the Node-Splitting Method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502676a",
   "metadata": {},
   "source": [
    "Over the years, there has been significant progress in this area, leading to more efficient implementations of persistent data structures.\n",
    "\n",
    "The paper titled \"Partially Persistent Data Structures of Bounded Degree with Constant Update Time\" by Gerth Stølting Brodal (1996) presents a method for making data structures partially persistent while guaranteeing constant worst-case time for updates and access operations — a significant improvement over earlier techniques that only offered amortized efficiency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e482a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"design\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Algorithms Design\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825d1e9",
   "metadata": {},
   "source": [
    "## Persistent Linked List\n",
    "\n",
    "The persistent linked list contains Nodes that have pointers to the next Node and also may contain a version tracker. When we want to modify the list, instead of changing the existing nodes, we simply create new ones. When a new Node is created, it becomes the head of the list and points to the old head.\n",
    "\n",
    "### Structure\n",
    "\n",
    "The persistent linked list is based on the structure of a normal linked list. Every Node on the list has a pointer to the next Node. The list object contains a point5er to its head (first Node on the list).\n",
    "- PersistentLinkedList\n",
    "    - head (First Node of the List)\n",
    "    - version (Version of the List)\n",
    "- Node\n",
    "    - value (Object the Node carry)\n",
    "    - version (Version of the List on wich the Node was created)\n",
    "    - next (Pointer to the next Node on the List)\n",
    "\n",
    "### Operations\n",
    "\n",
    "- Add: Insert a new Node on the List. \n",
    "- Remove: Remove a Node from the List.\n",
    "\n",
    "### Limitations\n",
    "- Consumes more memory than traditional linked lists due to multiple versions.\n",
    "- More difficult to implement than traditional linked lists.\n",
    "- Due to the need to create new Nodes, it may be slower than traditional linked lists.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc59ab",
   "metadata": {},
   "source": [
    "<center><img src='https://raw.githubusercontent.com/GoncaloP0710/Desenho-Anlise-Algoritmos/master/imgs/Purely_functional_list_after.png' width=500px></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd184854",
   "metadata": {},
   "source": [
    "## Partially persistent data structure - Balanced search tree[2], [4]\n",
    "\n",
    "This model can be implemented using a balanced binary search tree (bst) with a couple of changes. A binary tree is balanced if the height of the tree is O(Log n) where n is the number of nodes. \n",
    "\n",
    "First we need to implement the 'Fat Node' method wich states that all the changes to a node must be recorded and the old values must not be lost. That means that all the fields of a node must have a version stamp associated to it.\n",
    "\n",
    "Secondly, in order to counter the limitation that a node becomes obselite after a change, the 'Node-Copying Method' was invented. It forces nodes to hold a specific number of atributes and once there is no more space for them, a new copy of the node is made with only the new field values. All the predecessors most contain a pointer for the new node and if they dont have space for the new pointer, they also must be copied. \n",
    "\n",
    "Finaly, the path copying property must be acomplished. It states that a copy of all the nodes in the same path as the one that suffered changes mut be copied and all the other ones that point to it must point to the new one that was created due to the changes made. \n",
    "\n",
    "### Structure\n",
    "\n",
    "The persistent balanced search tree is based on the structure of a normal binary search tree. Every Node on the tree has a list of pointers and a list of fields.\n",
    "\n",
    "- Field\n",
    "    - name (Alias of the object)\n",
    "    - value (Object the field carry)\n",
    "    - version (Version of the field)\n",
    "- FatNode\n",
    "    - max_fields (Number of fields a Node can have at max)\n",
    "    - fields (List of fields the Node has)\n",
    "    - right (List of pointers to the next Node on the right)\n",
    "    - left (List of pointers to the next Node on the left)\n",
    "    - order (Index of the Node)\n",
    "- PartiallyPersistentBST\n",
    "    - max_fields (Number of fields a Node can have at max)\n",
    "    - counter (Number of the current version of the tree)\n",
    "    - nodes (Dictionary of the Nodes in the tree)\n",
    "    - root (First node of the tree)\n",
    "\n",
    "### Operations\n",
    "\n",
    "- Insert (Insert a new FatNode into the tree)\n",
    "- Find (Find the value of a field on the tree)\n",
    "- Delete (Delete the latest version of the given field)\n",
    "- IsBalanced (Check if tree is balanced)\n",
    "- Rebalance (Rebalance the tree)\n",
    "- Height (Calculate the height of the tree)\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- You can’t modify old versions — only the latest one can be updated.\n",
    "- New version created on every update, which can increase memory usage over time.\n",
    "\n",
    "### Fully persistent data structure - Balanced search tree[4]\n",
    "\n",
    "One of the problems of Fully Persistent compared to only Partially Persistent, where its versions have a natural linear order, is the fact that the order becomes partially ordered.\n",
    "\n",
    "This problem can be addressed with a version list which can be represented by a tree. When a new version is created, a new node can be inserted after its parent.\n",
    "\n",
    "The differences in the Fat Node method are the following ones:\n",
    "\n",
    "- Versions of the node are now related to the version tree and no longer to a numeric value.\n",
    "\n",
    "- The update now takes one more action. The new fat node is created after adding a new node to the version list.\n",
    "\n",
    "As well as the Fat Node method, the Node Copying also changed to a different variant named Node-Splitting Method. It differs from the previous one because now only half the attributes of the node are sent to the new one, that way leaving space on both nodes (the old and the new).\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- More difficult to implement than partial persistence\n",
    "- Branching versions can lead to faster memory growth, especially if changes are frequent or deep.\n",
    "- Multiple active branches may make the logic and debugging of versioned behavior more complex.\n",
    "- Some operations on older versions may become slower (e.g., in ropes or trees) due to versioning overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b027b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"implementation\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Implementation\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a891a7",
   "metadata": {},
   "source": [
    "# Persistent Linked List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1a7ca3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# ----------------------- Node Class -----------------------\n",
    "# ==========================================================\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, value: object, version: int, next: 'Node' = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize a Node with a value and a reference to the next node.\n",
    "        :param value: The value stored in the node.\n",
    "        :param version: The version of the node.\n",
    "        :param next: A reference to the next node in the list.\n",
    "        :return: A new Node object.\n",
    "        \"\"\"\n",
    "        self.value = value\n",
    "        self.version = version\n",
    "        self.next = next\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        Return a string representation of the Node.\n",
    "        :return: A string representation of the Node.\n",
    "        \"\"\"\n",
    "        return f\"Node({self.value}, {self.version}, {self.next})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# ---------------- Persistent Linked List Class ------------\n",
    "# ===========================================================\n",
    "\n",
    "class PersistentLinkedList:\n",
    "    def __init__(self, head: Node = None, version: int = 0) -> None:\n",
    "        \"\"\"\n",
    "        Initialize a Persistent Linked List with a head node.\n",
    "        :param head: The head node of the list.\n",
    "        :param version: The version of the list.\n",
    "        :return: A new PersistentLinkedList object.\n",
    "        \"\"\"\n",
    "        self.head = head\n",
    "        self.version = version\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        Return a string representation of the Persistent Linked List.\n",
    "        :return: A string representation of the Persistent Linked List.\n",
    "        \"\"\"\n",
    "        return self.head.__repr__() if self.head else \"Empty List\"\n",
    "    \n",
    "    def add(self, value: object) -> 'PersistentLinkedList':\n",
    "        \"\"\"\n",
    "        Add a new value to the list and return a new version of the list.\n",
    "        :param value: The value to be added.\n",
    "        :return: A new PersistentLinkedList with the added value.\n",
    "        \"\"\"\n",
    "        new_node = Node(value, self.version, self.head)\n",
    "        return PersistentLinkedList(new_node, self.version + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e18c28dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pllV1: Node(1, 0, None)\n",
      "pllV2: Node(2, 1, Node(1, 0, None))\n",
      "pllV3: Node(3, 2, Node(2, 1, Node(1, 0, None)))\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# --------------------- Example Usage ---------------------\n",
    "# =========================================================\n",
    "\n",
    "pll = PersistentLinkedList()\n",
    "pllV1 = pll.add(1)\n",
    "pllV2 = pllV1.add(2)\n",
    "pllV3 = pllV2.add(3)\n",
    "\n",
    "print(\"pllV1:\", pllV1)\n",
    "print(\"pllV2:\", pllV2)\n",
    "print(\"pllV3:\", pllV3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04bd80a",
   "metadata": {},
   "source": [
    "# Partially persistent data structure\n",
    "- Fat-Node Method\n",
    "- Node-Copying Method\n",
    "- Balanced Binary Search Tree\n",
    "\n",
    "This implementation is based on the paper: \"Making Data Structures Persistent\" [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Dict, Tuple\n",
    "import hashlib\n",
    "\n",
    "# =========================================================\n",
    "# ---------------------- Field Class ----------------------\n",
    "# =========================================================\n",
    "\n",
    "class Field:\n",
    "    def __init__(self, name: str, value: object, version: int):\n",
    "        \"\"\"\n",
    "        Initialize a Field with a name, value, and version.\n",
    "        :param name: The name of the field.\n",
    "        :param value: The value of the field.\n",
    "        :param version: The version of the field.\n",
    "        :return: A new Field object.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "        self.version = version # satisfy the Fat-Node Method\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Return a string representation of the Field.\n",
    "        :return: A string representation of the Field.\n",
    "        \"\"\"\n",
    "        return(\n",
    "            f\"Field(\\n\"\n",
    "            f\"  name={self.name},\\n\"\n",
    "            f\"  value={self.value},\\n\"\n",
    "            f\"  version={self.version},\\n\"\n",
    "            f\")\"\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91446a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# --------------------- FatNode Class ---------------------\n",
    "# =========================================================\n",
    "\n",
    "class FatNode:\n",
    "    def __init__(self, max_fields: int, counter: int):\n",
    "        \"\"\"\n",
    "        Initialize a FatNode with a maximum number of fields and a counter.\n",
    "        :param max_fields: The maximum number of fields in the node.\n",
    "        :param counter: The counter used to generate a unique identifier for the node.\n",
    "        :return: A new FatNode object.\n",
    "        \"\"\"\n",
    "        self.max_fields = max_fields # satisfy the Node-Copying Method\n",
    "        self.fields = []\n",
    "        self.right = []\n",
    "        self.left = []\n",
    "        self.order = custom_hash(counter) # used to decide where to insert in the tree\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Return a string representation of the FatNode.\n",
    "        :return: A string representation of the FatNode.\n",
    "        \"\"\"\n",
    "        def format_children(children):\n",
    "            return [{\"name\": field.name, \"version\": field.version} for child in children for field in child.fields]\n",
    "\n",
    "        return (\n",
    "            f\"FatNode(\\n\"\n",
    "            f\"  max_fields={self.max_fields},\\n\"\n",
    "            f\"  fields={self.fields},\\n\"\n",
    "            f\"  right={format_children(self.right)},\\n\"\n",
    "            f\"  left={format_children(self.left)},\\n\"\n",
    "            f\")\"\n",
    "        )\n",
    "    \n",
    "    def _add_field(self, other):\n",
    "        \"\"\"\n",
    "        Add a field to the FatNode. If a field with the same name and version already exists, it will be updated.\n",
    "        :param other: The field to be added.\n",
    "        :return: The updated FatNode.\n",
    "        \"\"\"\n",
    "        if isinstance(other, Field):\n",
    "            if self.fields is None:\n",
    "                self.fields = [other]\n",
    "            else:\n",
    "                # Check if a field with the same name and version already exists\n",
    "                for field in self.fields:\n",
    "                    if field.name == other.name and field.version == other.version:\n",
    "                        field.value = other.value\n",
    "                        return\n",
    "                if len(self.fields) >= self.max_fields:\n",
    "                    raise OverflowError(\"No space left for new field in fat node.\")\n",
    "                self.fields.append(other)\n",
    "            return self\n",
    "        else:\n",
    "            raise TypeError(\"Unsupported operand type(s) for +: 'FatNode' and '{}'\".format(type(other).__name__))\n",
    "        \n",
    "    def add_fields(self, fields: List[Tuple[str, object]], counter: int):\n",
    "        \"\"\"\n",
    "        Add multiple fields to the FatNode. If a field with the same name and version already exists, it will be updated.\n",
    "        :param fields: A list of tuples containing the name and value of the fields to be added.\n",
    "        :param counter: The counter used to generate a unique identifier for the node.\n",
    "        :return: The updated FatNode.\n",
    "        \"\"\"\n",
    "        for name, value in fields:\n",
    "            field = Field(name, value, counter)\n",
    "            self._add_field(field)\n",
    "        return self\n",
    "    \n",
    "    def get_latest_child(self, right: bool) -> Optional['FatNode']: # used to traverse the tree\n",
    "        \"\"\"\n",
    "        Get the latest child node based on the order attribute. If right is True, it will return the right child, otherwise the left child.\n",
    "        :param right: A boolean indicating whether to return the right child or the left child.\n",
    "        :return: The latest version of the child node.\n",
    "        \"\"\"\n",
    "        children = self.right if right else self.left\n",
    "        return max(children, key=lambda child: child.order, default=None)\n",
    "    \n",
    "def custom_hash(value: int) -> str:\n",
    "    \"\"\"\n",
    "    Generate a SHA-256 hash for the given integer. Used to create a unique identifier for the node and improve performance.\n",
    "    :param value: The integer to be hashed.\n",
    "    :return: The SHA-256 hash of the integer as a hexadecimal string.\n",
    "    \"\"\"\n",
    "    value_bytes = str(value).encode('utf-8')\n",
    "    hash_object = hashlib.sha256(value_bytes)\n",
    "    return hash_object.hexdigest()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf181179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# ---------------- PartiallyPersistentBST Class -----------\n",
    "# =========================================================\n",
    "\n",
    "class PartiallyPersistentBST:\n",
    "\n",
    "    def __init__(self, max_fields: int):\n",
    "        \"\"\"\n",
    "        Initialize a Partially Persistent Binary Search Tree with a maximum number of fields.\n",
    "        :param max_fields: The maximum number of fields in each node.\n",
    "        :return: A new PartiallyPersistentBST object.\n",
    "        \"\"\"\n",
    "        self.max_fields = max_fields\n",
    "        self.counter = 0\n",
    "        self.nodes: Dict[int, FatNode] = {}\n",
    "        self.root: Optional[FatNode] = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Return a string representation of the Partially Persistent Binary Search Tree.\n",
    "        :return: A string representation of the Partially Persistent Binary Search Tree.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            f\"PartiallyPersistentBST(\\n\"\n",
    "            f\"  max_fields={self.max_fields},\\n\"\n",
    "            f\"  index={self.counter},\\n\"\n",
    "            f\"  nodes={self.nodes},\\n\" \n",
    "            f\")\"\n",
    "        )\n",
    "        \n",
    "    def insert(self, fields: List[Tuple[str, object]]):\n",
    "        \"\"\"\n",
    "        Insert a new FatNode into the tree.\n",
    "        \"\"\"\n",
    "        if self.counter == 0:\n",
    "            try:\n",
    "                new_node = FatNode(self.max_fields, self.counter)\n",
    "                new_node.add_fields(fields, self.counter)\n",
    "                self.nodes[self.counter] = new_node\n",
    "                self.root = new_node\n",
    "                self.counter += 1\n",
    "            except OverflowError:\n",
    "                self._copy_node(fields)\n",
    "        else:\n",
    "            self._insert(self.root, fields, self.counter)\n",
    "    \n",
    "    def _insert (self, node: FatNode, fields: List[Tuple[str, object]], order: int):\n",
    "        direction = 'left' if custom_hash(order) < node.order else 'right'\n",
    "        is_right = direction == 'right'\n",
    "        child_list = getattr(node, direction)\n",
    "\n",
    "        if not child_list:\n",
    "            try:\n",
    "                new_node = FatNode(self.max_fields, order)\n",
    "                new_node.add_fields(fields, order)\n",
    "                child_list.append(new_node)\n",
    "                self.nodes[self.counter] = new_node\n",
    "                self.counter += 1\n",
    "                self._rebalance()\n",
    "                return\n",
    "            except OverflowError:\n",
    "                self._copy_node(fields)\n",
    "        else:\n",
    "            return self._insert(node.get_latest_child(is_right), fields, order)\n",
    "\n",
    "    def find(self, name: str, version: int) -> Optional[object]:\n",
    "        \"\"\"\n",
    "        Find the value of a field with the given name and version.\n",
    "        :param name: The name of the field to be found.\n",
    "        :param version: The version of the field to be found.\n",
    "        :return: The value of the field if found, otherwise None.\n",
    "        \"\"\"\n",
    "        if self.nodes:\n",
    "            node = self._find(self.root, version)\n",
    "            if node:\n",
    "                for field in node.fields:\n",
    "                    if field.name == name and field.version == version:\n",
    "                        return field.value\n",
    "        return None\n",
    "    \n",
    "    def _find(self, node: FatNode, version: int) -> Optional[FatNode]:\n",
    "        if node:\n",
    "            if node.order == custom_hash(version):\n",
    "                return node\n",
    "            elif node.order > custom_hash(version):\n",
    "                return self._find(node.get_latest_child(False), version)\n",
    "            else:\n",
    "                return self._find(node.get_latest_child(True), version)\n",
    "        return None\n",
    "    \n",
    "    def delete(self, name: str):\n",
    "        \"\"\"\n",
    "        Delete a field with the given name. only the latest version will be deleted.\n",
    "        :param name: The name of the field to be deleted.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if self.nodes:\n",
    "            node = self._find(self.root, self.counter-1)\n",
    "            if node:\n",
    "                for field in node.fields:\n",
    "                    if field.name == name:\n",
    "                        node.fields.remove(field)\n",
    "                        return\n",
    "                    \n",
    "    def _is_balanced(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the tree is balanced.\n",
    "        A tree is balanced if the height difference between the left and right subtrees is at most 1.\n",
    "        \"\"\"\n",
    "        if not self.root: # Tree is empty\n",
    "            return True\n",
    "        left_height = self._height(self.root.get_latest_child(False))\n",
    "        right_height = self._height(self.root.get_latest_child(True))\n",
    "        return abs(left_height - right_height) <= 1\n",
    "    \n",
    "    def _rebalance(self):\n",
    "        \"\"\"\n",
    "        Rebalance the tree if it is unbalanced.\n",
    "        \"\"\"\n",
    "        if not self._is_balanced():\n",
    "            flat_nodes = self._flatten_tree(self.root)\n",
    "            balanced_root = self._build_balanced_tree(flat_nodes)\n",
    "            self.root = balanced_root\n",
    "\n",
    "            new_node_map = {}\n",
    "            self._rebuild_node_map(balanced_root, new_node_map)\n",
    "            self.nodes = new_node_map\n",
    "\n",
    "\n",
    "    def _build_balanced_tree(self, nodes: List[FatNode]) -> Optional[FatNode]:\n",
    "        \"\"\"\n",
    "        Recursively build a balanced BST from sorted FatNodes.\n",
    "        Got help from Co-Pilot to implement this method.\n",
    "        \"\"\"\n",
    "        if not nodes:\n",
    "            return None\n",
    "\n",
    "        mid = len(nodes) // 2\n",
    "        root = nodes[mid]\n",
    "\n",
    "        # Clear child lists before rebuilding to avoid linking old state\n",
    "        root.left = []\n",
    "        root.right = []\n",
    "\n",
    "        left_child = self._build_balanced_tree(nodes[:mid])\n",
    "        right_child = self._build_balanced_tree(nodes[mid+1:])\n",
    "\n",
    "        if left_child:\n",
    "            root.left.append(left_child)\n",
    "        if right_child:\n",
    "            root.right.append(right_child)\n",
    "\n",
    "        return root\n",
    "    \n",
    "    def _rebuild_node_map(self, node: Optional[FatNode], nodes_map: Dict[int, FatNode]):\n",
    "        \"\"\"\n",
    "        Rebuild the node map with the latest version of each FatNode (cause the right and left child may be changed).\n",
    "        \"\"\"\n",
    "        if node is None:\n",
    "            return\n",
    "        for field in node.fields:\n",
    "            nodes_map[field.version] = node\n",
    "        self._rebuild_node_map(node.get_latest_child(False), nodes_map)\n",
    "        self._rebuild_node_map(node.get_latest_child(True), nodes_map)\n",
    "\n",
    "\n",
    "    def _flatten_tree(self, node: Optional[FatNode]) -> List[FatNode]:\n",
    "        \"\"\"\n",
    "        In-order traversal to flatten the tree into a list.\n",
    "        Got help from Co-Pilot to implement this method.\n",
    "        \"\"\"\n",
    "        if node is None:\n",
    "            return []\n",
    "        \n",
    "        left = self._flatten_tree(node.get_latest_child(False))\n",
    "        right = self._flatten_tree(node.get_latest_child(True))\n",
    "        \n",
    "        return left + [node] + right\n",
    "\n",
    "    def _height(self, node: FatNode) -> int:\n",
    "        \"\"\"\n",
    "        Calculate the height of the tree.\n",
    "        The height of a tree is the number of edges on the longest path from the root to a leaf.\n",
    "        \"\"\"\n",
    "        if node is None:\n",
    "            return 0\n",
    "        left_height = self._height(node.get_latest_child(False))\n",
    "        right_height = self._height(node.get_latest_child(True))\n",
    "        return max(left_height, right_height) + 1\n",
    "\n",
    "    def _copy_node(self, fields: List[Tuple[str, object]]):\n",
    "        \"\"\"\n",
    "        Node-Copying Method -> Used when a node is full of fields. Create more nodes to store the fields.\n",
    "        \"\"\"\n",
    "        fields_divided = self._divide_fields(fields)\n",
    "        if len(fields_divided[0]) > self.max_fields or len(fields_divided[1]) > self.max_fields:\n",
    "            self._copy_node(fields_divided[0])\n",
    "            self._copy_node(fields_divided[1])    \n",
    "            return\n",
    "        if len(fields_divided[0]) > 0:\n",
    "            self.insert(fields_divided[0])\n",
    "        if len(fields_divided[1]) > 0:\n",
    "            self.insert(fields_divided[1])\n",
    "\n",
    "    def _divide_fields(self, fields: List[Tuple[str, object]]) -> Tuple[Tuple[str, object], Tuple[str, object]]:\n",
    "        \"\"\"\n",
    "        Divide the fields into two lists.\n",
    "        \"\"\"\n",
    "        mid = len(fields) // 2\n",
    "        return fields[:mid], fields[mid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e3c89708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartiallyPersistentBST(\n",
      "  max_fields=2,\n",
      "  index=7,\n",
      "  nodes={0: FatNode(\n",
      "  max_fields=2,\n",
      "  fields=[Field(\n",
      "  name=a,\n",
      "  value=10,\n",
      "  version=0,\n",
      ")],\n",
      "  right=[{'name': 'g', 'version': 2}],\n",
      "  left=[{'name': 'h', 'version': 3}, {'name': 'i', 'version': 3}],\n",
      "), 3: FatNode(\n",
      "  max_fields=2,\n",
      "  fields=[Field(\n",
      "  name=h,\n",
      "  value=90,\n",
      "  version=3,\n",
      "), Field(\n",
      "  name=i,\n",
      "  value=100,\n",
      "  version=3,\n",
      ")],\n",
      "  right=[],\n",
      "  left=[{'name': 'j', 'version': 4}],\n",
      "), 4: FatNode(\n",
      "  max_fields=2,\n",
      "  fields=[Field(\n",
      "  name=j,\n",
      "  value=110,\n",
      "  version=4,\n",
      ")],\n",
      "  right=[],\n",
      "  left=[],\n",
      "), 2: FatNode(\n",
      "  max_fields=2,\n",
      "  fields=[Field(\n",
      "  name=g,\n",
      "  value=80,\n",
      "  version=2,\n",
      ")],\n",
      "  right=[{'name': 'p', 'version': 5}],\n",
      "  left=[{'name': 'b', 'version': 1}, {'name': 'c', 'version': 1}],\n",
      "), 1: FatNode(\n",
      "  max_fields=2,\n",
      "  fields=[Field(\n",
      "  name=b,\n",
      "  value=20,\n",
      "  version=1,\n",
      "), Field(\n",
      "  name=c,\n",
      "  value=30,\n",
      "  version=1,\n",
      ")],\n",
      "  right=[],\n",
      "  left=[],\n",
      "), 5: FatNode(\n",
      "  max_fields=2,\n",
      "  fields=[Field(\n",
      "  name=p,\n",
      "  value=170,\n",
      "  version=5,\n",
      ")],\n",
      "  right=[],\n",
      "  left=[{'name': 's', 'version': 6}],\n",
      "), 6: FatNode(\n",
      "  max_fields=2,\n",
      "  fields=[Field(\n",
      "  name=s,\n",
      "  value=200,\n",
      "  version=6,\n",
      ")],\n",
      "  right=[],\n",
      "  left=[],\n",
      ")},\n",
      ")\n",
      "10\n",
      "170\n",
      "Is the tree balanced? True\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# --------------------- Example Usage ---------------------\n",
    "# =========================================================\n",
    "\n",
    "bst = PartiallyPersistentBST(max_fields=2)\n",
    "bst.insert([(\"a\", 10), (\"b\", 20), (\"c\", 30)])\n",
    "bst.insert([(\"g\", 80), (\"h\", 90), (\"i\", 100)])\n",
    "bst.insert([(\"j\", 110)])\n",
    "bst.insert([(\"p\", 170)])\n",
    "bst.insert([(\"s\", 200)])\n",
    "\n",
    "print(bst)\n",
    "print(bst.find(\"a\", 0))\n",
    "print(bst.find(\"p\", 5))\n",
    "\n",
    "print(f\"Is the tree balanced? {bst._is_balanced()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a6f87",
   "metadata": {},
   "source": [
    "<a id=\"analysis\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Complexity analysis\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329d1b3",
   "metadata": {},
   "source": [
    "# Persistent Linked List\n",
    "\n",
    "The add method of the data structure has a complexity of O(1) because it does not traverse or modify the existing list, it simply creates a new version.\n",
    "\n",
    "The only method that has a different complexity is the __repr__ with O(n) due to the fact it traverses the entire list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876fa30",
   "metadata": {},
   "source": [
    "# Partially persistent data structure - Balanced  Binary Search Tree\n",
    "\n",
    "Based on the paper that inspired the structure, the fat node method in the worst case presents an O(log n) time and an O(1) space complexity per update. The node-copying method is said to have a worst case of O(1) amortized and O(1) in time and space complexity, respectively.\n",
    "\n",
    "The insert method can have multiple cases of a difference in its complexity. In the best case, the tree is empty and there will be no need to use node-copying, then it will have a time complexity of O(1). The worst case would involve node-copying and balancing the tree.\n",
    "\n",
    "To check if the tree is balanced, the time complexity of the operation is O(n), and in the best case O(1) if the tree is empty. This is because the function _height traverses every node no matter what.\n",
    "\n",
    "If the tree needs to be balanced, the time complexity of the operation would be O(n). Firstly, it uses the function _flatten_tree that performs an in-order traversal of the tree, meaning a complexity of O(n). Secondly, it calls the _build_balanced_tree function that is also O(n). Finally, the _rebuild_node_map function traverses the whole tree again to update the node_map, meaning it has a complexity of O(n) as well.\n",
    "\n",
    "The best case for the find and delete operation is if the node is root. If that's the case, the complexity will be O(1). If not, then we will have a complexity of O(log n).\n",
    "\n",
    "Finally, the copy_node operation must divide the fields and then insert nodes into the tree. The division of the fields is made with a time of O(1). For every copy of the node, the tree will have to be traversed (O(log n)), and in the worst case, balance the tree (O(n)). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83477900",
   "metadata": {},
   "source": [
    "<a id=\"exercise\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Exercise\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4af8a4",
   "metadata": {},
   "source": [
    "# Debugging\n",
    "\n",
    "Because a partially persistent data structure allows us to access previous states, we can, for example, store different versions of the same variable and implement a rudimentary debugging tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b3947609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def test_function(counter, max_calls=100):\n",
    "    \"\"\"\n",
    "    A recursive function that randomly decrements the counter but stops after 100 calls.\n",
    "    \"\"\"\n",
    "    if max_calls == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        decrement = random.randint(0, 20)\n",
    "        return test_function(counter - decrement, max_calls - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c7f613b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'counter': -574, 'max_calls': 40, 'decrement': 2}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "bst = PartiallyPersistentBST(max_fields=2)\n",
    "\n",
    "def trace(frame, event, arg):\n",
    "    if event == \"line\" and frame.f_lineno == 10:\n",
    "        bst.insert([(str(frame.f_lineno), frame.f_locals)])\n",
    "    return trace\n",
    "\n",
    "def run_with_trace(func):\n",
    "    sys.settrace(trace)\n",
    "    try:\n",
    "        result = func()\n",
    "    finally:\n",
    "        sys.settrace(None)\n",
    "    return result\n",
    "\n",
    "run_with_trace(lambda: test_function(10))\n",
    "\n",
    "# 10 represents the line number and 60 represents the version (the counter)\n",
    "print(bst.find(\"10\", 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623a260",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id=\"references\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=References\" width=\"600\"/>\n",
    "\n",
    "\n",
    "### Articles and Tutorials\n",
    "1. [Introduction to Persistent Data Structures](https://arpitbhayani.me/blogs/persistent-data-structures-introduction/) - A beginner-friendly overview of persistent data structures.\n",
    "2. [Partial Persistence](https://sungsoo.github.io/2014/01/18/partial-persistence.html) - A concise explanation of partial persistence.\n",
    "3. [Introduction to Balanced Binary Tree](https://www.geeksforgeeks.org/balanced-binary-tree/) - A beginner-friendly overview of Balanced Binary Trees\n",
    "\n",
    "### Research Papers\n",
    "4. [Making Data Structures Persistent](https://www.cs.cmu.edu/~sleator/papers/making-data-structures-persistent.pdf) - The foundational paper by Driscoll, Sarnak, Sleator, and Tarjan (1986) introducing persistent data structures.\n",
    "5. [Partially Persistent Data Structures of Bounded Degree with Constant Update Time](https://www.cs.au.dk/~gerth/papers/njc96.pdf) - Gerth Stølting Brodal's seminal paper on partially persistent data structures.\n",
    "6. [Partial Persistence in Object-Oriented Languages](https://fpluquet.be/Publications_&_Talks_files/Implementing%20Partial%20Persistence%20in%20Object-Oriented%20Languages.pdf) - The paper presents a way to making data structures partially persistent in object-oriented programming languages, specifically Java.\n",
    "7. [Persistence in Data Structures](https://arxiv.org/pdf/1301.3388) - A modern exploration of persistence in data structures.\n",
    "8. [MIT Advanced Algorithms Lecture Notes](https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2005/2165d83010dc7633bce397ea75f889f9_lec05_1999.pdf) - Lecture notes discussing persistence in data structures.\n",
    "\n",
    "\n",
    "### Online Guides\n",
    "9. [USACO Guide: Persistent Data Structures](https://usaco.guide/adv/persistent?lang=cpp) - A practical guide for competitive programming.\n",
    "\n",
    "### Encyclopedic Resources\n",
    "10. [Wikipedia: Persistent Data Structure](https://en.wikipedia.org/wiki/Persistent_data_structure) - A general overview of persistent data structures.\n",
    "\n",
    "### Additional Resources\n",
    "11. [Lirias Repository](https://lirias.kuleuven.be/retrieve/19369) - A collection of academic resources on persistence.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
