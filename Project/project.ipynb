{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31113be5",
   "metadata": {},
   "source": [
    "# Persistent Data Structures\n",
    "\n",
    "#### Goncalo Pinto - fc58178\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<a href=\"#introduction\"><kbd> <br>Introduction<br> </kbd></a>&ensp;&ensp;\n",
    "<a href=\"#motivation\"><kbd> <br>Motivation & historical background<br> </kbd></a>&ensp;&ensp;\n",
    "<a href=\"#design\"><kbd> <br>Design of the algorithms<br> </kbd></a>&ensp;&ensp;\n",
    "<a href=\"#reference\"><kbd> <br>References<br> </kbd></a>&ensp;&ensp;\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed9b1e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "---\n",
    "<a id=\"introduction\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Introduction\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b873b42b",
   "metadata": {},
   "source": [
    "A persistent data structure is a data structure that preserves the previous counters of itself when modified, allowing access to any historical counter. In other words, once a change is made to the structure, both the original and modified counters remain accessible. This is particularly useful in scenarios where you need to keep track of the history of updates or backtrack to previous states of the data structure.\n",
    "\n",
    "- A data structure is `partially persistent` if all counters can be accessed but only the newest counter can be modified. \n",
    "\n",
    "- `Fully persistent` if every counter can be both accessed and modified. \n",
    "\n",
    "- `Confluently persistent` is when we merge two or more counters to get a new counter.\n",
    "\n",
    "These types of data structures are particularly common in logical and functional programming, as languages in those paradigms discourage (or fully forbid) the use of mutable data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae0132",
   "metadata": {},
   "source": [
    "## Partially persistent data structure\n",
    "\n",
    "A partially persistent data structure is a data structure in which old versions are remembered and can always be inspected. However, only the latest version of the data structure can be modified.\n",
    "\n",
    "General theoretical schemes are known (e.g. the fat node method ) for making any data structure partially persistent.\n",
    "\n",
    "#### Pros\n",
    "\n",
    "- You can query any previous version of the data structure\n",
    "- Simpler to implement and more efficient than fully or confluently persistent structures.\n",
    "- Number of versions and extra memory needed is often limited.\n",
    "- Worst-case guarantees, updates and queries are predictable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067be8c",
   "metadata": {},
   "source": [
    "## Fully persistent data structure\n",
    "\n",
    "A fully persistent structure offers accesses to its previous versions for queries and updates, where each update operation on a version of the data structure creates a new branch from this version for the new version.\n",
    "\n",
    "In a fully persistent structure, if update operation i applies to version j < i, the result of the update is version i; version j is not changed by the update. We denote by n the number of nodes in the current version.\n",
    "\n",
    "#### Pros\n",
    "\n",
    "- You can update any version, not just the latest — each update creates a new branch in the version tree.\n",
    "- Ideal for situations where different branches of computation must operate independently from the same data snapshot.\n",
    "- Old versions remain unchanged, ensuring reproducibility and safety.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ad8dd",
   "metadata": {},
   "source": [
    "## Confluently persistent data structure\n",
    "\n",
    "A data structure is called confluently persistent if there is a meld operation that creates a new version from two previous versions so that branches in a version tree are joined and a version DAG is formed.\n",
    "\n",
    "Confluently Persistent Sets and Maps are functional binary search trees that support efficient set operations both when operands are disjoint and when they are overlapping.\n",
    "\n",
    "#### Pros\n",
    "\n",
    "- Supports a meld operation: you can combine two or more past versions to create a new version\n",
    "- Unlike full persistence (which forms a tree), confluent persistence allows merging branches into a directed acyclic graph (DAG) of versions.\n",
    "- Ideal for use cases involving merging divergent states (distributed systems, version control...)\n",
    "- Excellent for multi-user environments or simulations that need to branch and later reconcile state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5bed0",
   "metadata": {},
   "source": [
    "<a id=\"motivation\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"motivation&historicalbackground\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Motivation &\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97517ee1",
   "metadata": {},
   "source": [
    "The motivation on the use and continuous work around \n",
    "Persistent data structures lies on the ability of maintaining previous states and enabling diferent operations on those.\n",
    "\n",
    "Some pratical exemples where this structures are optimaly used are:\n",
    "- Version Control (ex: git)\n",
    "- Undo/Redo Functionality (ex: text editor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c22198",
   "metadata": {},
   "source": [
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Background\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff3660",
   "metadata": {},
   "source": [
    "The concept of persistent data structure was introduced in Driscoll, Sarnak, Sleator, and Tarjan's 1986 article \"Making Data Structures Persistent\". \n",
    "\n",
    "The paper explores the advantages of using a data structure powerfull enghou to store previous stages of it self and compares it to a ephemeral one. It also exposed the 3 different types of persistence: Partial Persistence, Full Persistence and Confluent Persistence.\n",
    "\n",
    "The study intruduced different thecniques such as: The Fat Node Method, The Node-Copying Method or the The Node-Splitting Method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502676a",
   "metadata": {},
   "source": [
    "Over the years, there has been significant progress in this area, leading to more efficient implementations of persistent data structures.\n",
    "\n",
    "The paper titled \"Partially Persistent Data Structures of Bounded Degree with Constant Update Time\" by Gerth Stølting Brodal (1996) presents a method for making data structures partially persistent while guaranteeing constant worst-case time for updates and access operations — a significant improvement over earlier techniques that only offered amortized efficiency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e482a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"design\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Algorithms Design\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd184854",
   "metadata": {},
   "source": [
    "## Partially persistent data structure\n",
    "\n",
    "This model can be implemented using a balanced binary search tree (bst) with a couple of changes. A binary tree is balanced if the height of the tree is O(Log n) where n is the number of nodes. [2]\n",
    "\n",
    "First we need to implement the 'Fat Node' method wich states that all the changes to a node must be recorded and the old values must not be lost. That means that all the fields of a node must have a version stamp associated to it. [2] [4]\n",
    "\n",
    "Secondly, in order to counter the limitation that a node becomes obselite after a change, the 'Node-Copying Method' was invented. It forces nodes to hold a specific number of atributes and once there is no more space for them, a new copy of the node is made with only the new field values. All the predecessors most contain a pointer for the new node and if they dont have space for the new pointer, they also must be copied. [4]\n",
    "\n",
    "Finaly, the path copying property must be acomplished. It states that a copy of all the nodes in the same path as the one that suffered changes mut be copied and all the other ones that point to it must point to the new one that was created due to the changes made. [2]\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "- You can’t modify old versions — only the latest one can be updated.\n",
    "- New version created on every update, which can increase memory usage over time.\n",
    "- Requires extra logic for version tracking. Compared to regular (non-persistent) data structures, persistence adds code and logic complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce2d49",
   "metadata": {},
   "source": [
    "## Fully persistent data structure\n",
    "\n",
    "One of the problems of Fully persistent compared to only Partially persistent where its versions have a natural linear order is the fact that the order becomes partially ordered.\n",
    "\n",
    "This problem can be adressed with a version list wich can be represented by a tree. When a new version is created, a new node can be inserted after its parent.\n",
    "\n",
    "The differences in the Fat node method are the following ones:\n",
    "- Versions of the node are now related to the version tree and no longer to a numeric value.\n",
    "- The update now takes one more action. The new fat node is created after adding a new node to the version list.\n",
    "\n",
    "As well as the Fat node method, the node copying also changed to a diferent varient named Node-Splitting Method. It differs from the previous one cause now only half the atributes of the node are sent to the new one, that way leaving space on both nodes (the old and the new).\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "- More difficult to implement than partial persistence\n",
    "- Branching versions can lead to faster memory growth, especially if changes are frequent or deep.\n",
    "- Multiple active branches may make the logic and debugging of versioned behavior more complex.\n",
    "- Some operations on older versions may become slower (e.g., in ropes or trees) due to versioning overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0f7de",
   "metadata": {},
   "source": [
    "## Confluently persistent data structure\n",
    "\n",
    "\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "- Requires careful tracking of merged nodes and resolution of conflicts — significant algorithmic overhead.\n",
    "- If two merged versions changed the same data, you need a way to resolve which value wins.\n",
    "- Tracking and combining overlapping histories can result in significant duplication.\n",
    "- Ensuring structural invariants hold after merges adds implementation complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b027b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"implementation\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Implementation\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8c1a77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partially persistent data structure\n",
    "#   - Fat-Node Method\n",
    "#   - Node-Copying Method\n",
    "#   - Path-Copying Property\n",
    "\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "\n",
    "# =========================================================\n",
    "# ---------------------- Field Class ----------------------\n",
    "# =========================================================\n",
    "\n",
    "class Field:\n",
    "    def __init__(self, name: str, value: object, version: int):\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "        self.version = version # satisfy the Fat-Node Method\n",
    "\n",
    "    def __repr__(self):\n",
    "        return(\n",
    "            f\"Field(\\n\"\n",
    "            f\"  name={self.name},\\n\"\n",
    "            f\"  value={self.value},\\n\"\n",
    "            f\"  version={self.version},\\n\"\n",
    "            f\")\"\n",
    "        )\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, Field) and self.name == other.name and self.version == other.version and self.value == other.value\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.name, self.version, self.value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91446a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# --------------------- FatNode Class ---------------------\n",
    "# =========================================================\n",
    "\n",
    "class FatNode:\n",
    "    def __init__(self, max_fields: int, counter: int):\n",
    "        self.max_fields = max_fields # satisfy the Node-Copying Method\n",
    "        self.fields = []\n",
    "        self.right = []\n",
    "        self.left = []\n",
    "        self.order = hash(counter) # used to decide where to insert in the tree\n",
    "        self.copy_pointer = []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return(\n",
    "            f\"FatNode(\\n\"\n",
    "            f\"  max_fields={self.max_fields},\\n\"\n",
    "            f\"  fields={self.fields},\\n\"\n",
    "            f\"  right={self.right},\\n\"\n",
    "            f\"  left={self.left},\\n\"\n",
    "            f\")\"\n",
    "        ) \n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, FatNode) and self.max_fields == other.max_fields and self.fields == other.fields and self.right == other.right and self.left == other.left\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.max_fields, tuple(self.fields), self.right, self.left))\n",
    "    \n",
    "    def add_field(self, other):\n",
    "        if isinstance(other, Field):\n",
    "            if self.fields is None:\n",
    "                self.fields = [other]\n",
    "            else:\n",
    "                # Check if a field with the same name and version already exists\n",
    "                for field in self.fields:\n",
    "                    if field.name == other.name and field.version == other.version:\n",
    "                        field.value = other.value\n",
    "                        return\n",
    "                if len(self.fields) >= self.max_fields:\n",
    "                    raise OverflowError(\"No space left for new field in fat node.\")\n",
    "                self.fields.append(other)\n",
    "            return self\n",
    "        else:\n",
    "            raise TypeError(\"Unsupported operand type(s) for +: 'FatNode' and '{}'\".format(type(other).__name__))\n",
    "        \n",
    "    def add_fields(self, fields: List[Tuple[str, object]], counter: int):\n",
    "        for name, value in fields:\n",
    "            field = Field(name, value, counter)\n",
    "            self.add_field(field)\n",
    "        return self\n",
    "    \n",
    "    def get_latest_child(self, right: bool) -> Optional['FatNode']: # used to traverse the tree\n",
    "        children = self.right if right else self.left\n",
    "        return max(children, key=lambda child: child.order, default=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf181179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# ---------------- PartiallyPersistentBST Class -----------\n",
    "# =========================================================\n",
    "\n",
    "class PartiallyPersistentBST:\n",
    "\n",
    "    def __init__(self, max_fields: int):\n",
    "        self.max_fields = max_fields\n",
    "        self.counter = 0\n",
    "        self.nodes: Dict[int, FatNode] = {}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"PartiallyPersistentBST(\\n\"\n",
    "            f\"  max_fields={self.max_fields},\\n\"\n",
    "            f\"  index={self.counter},\\n\"\n",
    "            f\"  nodes={self.nodes},\\n\" \n",
    "            f\")\"\n",
    "        )\n",
    "        \n",
    "    def insert(self, fields: List[Tuple[str, object]]):\n",
    "        \"\"\"\n",
    "        Insert a new FatNode into the tree.\n",
    "        \"\"\"\n",
    "        if self.counter == 0:\n",
    "            try:\n",
    "                new_node = FatNode(self.max_fields, self.counter)\n",
    "                new_node.add_fields(fields, self.counter)\n",
    "                self.nodes[self.counter] = new_node\n",
    "                self.counter += 1\n",
    "                print(f\"Node {new_node.order} added to the root, with fields {new_node.fields}\")\n",
    "            except OverflowError:\n",
    "                self.copy_node(fields, self.counter)\n",
    "        else:\n",
    "            self._insert(self.nodes[0], fields, self.counter)\n",
    "    \n",
    "    def _insert(self, node: FatNode, fields: List[Tuple[str, object]], order: int):\n",
    "        if order < node.order:\n",
    "            if not node.left:\n",
    "                try:\n",
    "                    new_node = FatNode(self.max_fields, order)\n",
    "                    new_node.add_fields(fields, order)\n",
    "                    node.left.append(new_node)\n",
    "                    self.nodes[self.counter] = new_node\n",
    "                    self.counter += 1\n",
    "                    print(f\"Node {new_node.order} added to the left of {node.order}, with fields {new_node.fields}\")\n",
    "                    return\n",
    "                except OverflowError:\n",
    "                    self.copy_node(fields, order)\n",
    "            else:\n",
    "                return self._insert(node.get_latest_child(False), fields, order)\n",
    "        elif order > node.order:\n",
    "            if not node.right:\n",
    "                try:\n",
    "                    new_node = FatNode(self.max_fields, order)\n",
    "                    new_node.add_fields(fields, order)\n",
    "                    node.right.append(new_node)\n",
    "                    self.nodes[self.counter] = new_node\n",
    "                    self.counter += 1\n",
    "                    print(f\"Node {new_node.order} added to the right of {node.order}, with fields {new_node.fields}\")\n",
    "                    return\n",
    "                except OverflowError:\n",
    "                    self.copy_node(fields, order)\n",
    "            else:\n",
    "                return self._insert(node.get_latest_child(True), fields, order)\n",
    "\n",
    "    def find(self, name: str, version: int) -> Optional[object]:\n",
    "        \"\"\"\n",
    "        Find the value of a field with the given name and version.\n",
    "        \"\"\"\n",
    "        if self.nodes:\n",
    "            return self._find(self.nodes[0], name, version)\n",
    "        return None\n",
    "    \n",
    "    def _find(self, node: FatNode, name: str, version: int) -> Optional[object]:\n",
    "        if node:\n",
    "            if node.order == hash(version):\n",
    "                for field in node.fields:\n",
    "                    if field.name == name and field.version == version:\n",
    "                        return field.value\n",
    "                return None\n",
    "            elif node.order > hash(version):\n",
    "                return self._find(node.get_latest_child(False), name, version)\n",
    "            else:\n",
    "                return self._find(node.get_latest_child(True), name, version)\n",
    "        return None\n",
    "    \n",
    "    def delete(self, name: str):\n",
    "        \"\"\"\n",
    "        Delete a field with the given name and version.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    # -------------------------------- Auxiliary Methods -------------------------------\n",
    "\n",
    "    def copy_node(self, fields: List[Tuple[str, object]], version: int):\n",
    "        \"\"\"\n",
    "        Node-Copying Method -> Used when a node is full of fields. Create more nodes to store the fields.\n",
    "        \"\"\"\n",
    "        fields_divided = self.divide_fields(fields)\n",
    "        if len(fields_divided[0]) > self.max_fields or len(fields_divided[1]) > self.max_fields:\n",
    "            self.copy_node(fields_divided[0], self.counter)\n",
    "            self.copy_node(fields_divided[1], self.counter)    \n",
    "            return\n",
    "        if len(fields_divided[0]) > 0:\n",
    "            self.insert(fields_divided[0])\n",
    "        if len(fields_divided[1]) > 0:\n",
    "            self.insert(fields_divided[1])\n",
    "\n",
    "    def update_pointers(self, starting_version: int):\n",
    "        ...\n",
    "\n",
    "    def divide_fields(self, fields: List[Tuple[str, object]]) -> Tuple[Tuple[str, object], Tuple[str, object]]:\n",
    "        \"\"\"\n",
    "        Divide the fields into two lists.\n",
    "        \"\"\"\n",
    "        mid = len(fields) // 2\n",
    "        return fields[:mid], fields[mid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e3c89708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 added to the root, with fields [Field(\n",
      "  name=a,\n",
      "  value=10,\n",
      "  version=0,\n",
      ")]\n",
      "Node 1 added to the right of 0, with fields [Field(\n",
      "  name=b,\n",
      "  value=20,\n",
      "  version=1,\n",
      ")]\n",
      "Updating copy pointers from version 1 to 1\n",
      "Node 2 added to the right of 1, with fields [Field(\n",
      "  name=c,\n",
      "  value=30,\n",
      "  version=2,\n",
      ")]\n",
      "Updating copy pointers from version 2 to 2\n",
      "Node 3 added to the right of 2, with fields [Field(\n",
      "  name=c,\n",
      "  value=40,\n",
      "  version=3,\n",
      ")]\n",
      "Updating copy pointers from version 3 to 3\n",
      "Node 4 added to the right of 3, with fields [Field(\n",
      "  name=d,\n",
      "  value=50,\n",
      "  version=4,\n",
      ")]\n",
      "Updating copy pointers from version 4 to 4\n",
      "Updating copy pointers from version 3 to 4\n",
      "Updated copy_pointer of Node 3 to point to Node 4\n",
      "Node 5 added to the right of 4, with fields [Field(\n",
      "  name=e,\n",
      "  value=60,\n",
      "  version=5,\n",
      ")]\n",
      "Updating copy pointers from version 5 to 5\n",
      "Node 6 added to the right of 5, with fields [Field(\n",
      "  name=b,\n",
      "  value=70,\n",
      "  version=6,\n",
      ")]\n",
      "Updating copy pointers from version 6 to 6\n",
      "Updating copy pointers from version 5 to 6\n",
      "Updated copy_pointer of Node 5 to point to Node 6\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "bst = PartiallyPersistentBST(max_fields=1)\n",
    "bst.insert([(\"a\", 10), (\"b\", 20), (\"c\", 30)])\n",
    "bst.insert([(\"c\", 40), (\"d\", 50)])\n",
    "bst.insert([(\"e\", 60), (\"b\", 70)])\n",
    "\n",
    "print(bst.find(\"a\", 0))\n",
    "print(bst.find(\"b\", 1))\n",
    "print(bst.find(\"c\", 2))\n",
    "print(bst.find(\"c\", 3))\n",
    "print(bst.find(\"d\", 4))\n",
    "print(bst.find(\"e\", 5))\n",
    "print(bst.find(\"b\", 6))\n",
    "\n",
    "print(bst.nodes[1].copy_pointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a6f87",
   "metadata": {},
   "source": [
    "<a id=\"analysis\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Complexity analysis\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876fa30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83477900",
   "metadata": {},
   "source": [
    "<a id=\"exercise\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=Exercise\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4af8a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f613b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f623a260",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id=\"references\"></a>\n",
    "<img src=\"https://readme-typing-svg.herokuapp.com?font=Lexend+Giga&size=25&pause=1000&color=CCA9DD&vCenter=true&width=350&height=25&lines=References\" width=\"600\"/>\n",
    "\n",
    "\n",
    "### Articles and Tutorials\n",
    "1. [Introduction to Persistent Data Structures](https://arpitbhayani.me/blogs/persistent-data-structures-introduction/) - A beginner-friendly overview of persistent data structures.\n",
    "2. [Partial Persistence](https://sungsoo.github.io/2014/01/18/partial-persistence.html) - A concise explanation of partial persistence.\n",
    "3. https://www.geeksforgeeks.org/balanced-binary-tree/\n",
    "\n",
    "### Research Papers\n",
    "4. [Making Data Structures Persistent](https://www.cs.cmu.edu/~sleator/papers/making-data-structures-persistent.pdf) - The foundational paper by Driscoll, Sarnak, Sleator, and Tarjan (1986) introducing persistent data structures.\n",
    "5. [Partially Persistent Data Structures of Bounded Degree with Constant Update Time](https://www.cs.au.dk/~gerth/papers/njc96.pdf) - Gerth Stølting Brodal's seminal paper on partially persistent data structures.\n",
    "6. [Fully Persistent Lists with Catenation](https://www.cs.cmu.edu/~sleator/papers/another-persistence.pdf) - A paper discussing fully persistent lists and their applications.\n",
    "7. [Persistence in Data Structures](https://arxiv.org/pdf/1301.3388) - A modern exploration of persistence in data structures.\n",
    "8. [MIT Advanced Algorithms Lecture Notes](https://ocw.mit.edu/courses/6-854j-advanced-algorithms-fall-2005/2165d83010dc7633bce397ea75f889f9_lec05_1999.pdf) - Lecture notes discussing persistence in data structures.\n",
    "\n",
    "\n",
    "### Online Guides\n",
    "9. [USACO Guide: Persistent Data Structures](https://usaco.guide/adv/persistent?lang=cpp) - A practical guide for competitive programming.\n",
    "\n",
    "### Encyclopedic Resources\n",
    "10. [Wikipedia: Persistent Data Structure](https://en.wikipedia.org/wiki/Persistent_data_structure) - A general overview of persistent data structures.\n",
    "\n",
    "### Additional Resources\n",
    "11. [Lirias Repository](https://lirias.kuleuven.be/retrieve/19369) - A collection of academic resources on persistence.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
